# -*- coding: utf-8 -*-
"""abstractive text summerizationlarge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o14am2ibA6kurBby16XPnM3jaxk555y-
"""

!pip install transformers==2.8.0
!pip install torch==1.4.0

"""Importing modules"""

import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config

"""initializing the pretrained model"""

model= T5ForConditionalGeneration.from_pretrained('t5-large')
tokenizer=T5Tokenizer.from_pretrained('t5-large')
device= torch.device('cpu')

"""input text"""

text= """"
The major limitation in defining AI as simply “building machines that are intelligent” is that it doesn't actually explain what AI is and what makes a machine intelligent. AI is an interdisciplinary science with multiple approaches, but advancements in machine learning and deep learning are creating a paradigm shift in virtually every sector of the tech industry.

However, various new tests have been proposed recently that have been largely well received, including a 2019 research paper entitled “On the Measure of Intelligence.” In the paper, veteran deep learning researcher and Google engineer François Chollet argues that intelligence is the “rate at which a learner turns its experience and priors into new skills at valuable tasks that involve uncertainty and adaptation.” In other words: The most intelligent systems are able to take just a small amount of experience and go on to guess what would be the outcome in many varied situations.

Meanwhile, in their book Artificial Intelligence: A Modern Approach, authors Stuart Russell and Peter Norvig approach the concept of AI by unifying their work around the theme of intelligent agents in machines. With this in mind, AI is “the study of agents that receive percepts from the environment and perform actions.”

CHECK OUT THE TOP AI COMPANIES
View all AI Companies

Norvig and Russell go on to explore four different approaches that have historically defined the field of AI:

ARTIFICIAL INTELLIGENCE DEFINED: FOUR TYPES OF APPROACHES
Thinking humanly: mimicking thought based on the human mind.
Thinking rationally: mimicking thought based on logical reasoning.
Acting humanly: acting in a manner that mimics human behavior.
Acting rationally: acting in a manner that is meant to achieve a particular goal.
The first two ideas concern thought processes and reasoning, while the others deal with behavior. Norvig and Russell focus particularly on rational agents that act to achieve the best outcome, noting “all the skills needed for the Turing Test also allow an agent to act rationally.”

Former MIT professor of AI and computer science Patrick Winston defined AI as “algorithms enabled by constraints, exposed by representations that support models targeted at loops that tie thinking, perception and action together.”

While these definitions may seem abstract to the average person, they help focus the field as an area of computer science and provide a blueprint for infusing machines and programs with ML and other subsets of AI.
When one considers the computational costs and the technical data infrastructure running behind artificial intelligence, actually executing on AI is a complex and costly business. Fortunately, there have been massive advancements in computing technology, as indicated by Moore’s Law, which states that the number of transistors on a microchip doubles about every two years while the cost of computers is halved.

Although many experts believe that Moore’s Law will likely come to an end sometime in the 2020s, this has had a major impact on modern AI techniques — without it, deep learning would be out of the question, financially speaking. Recent research found that AI innovation has actually outperformed Moore’s Law, doubling every six months or so as opposed to two years.

By that logic, the advancements artificial intelligence has made across a variety of industries have been major over the last several years. And the potential for an even greater impact over the next several decades seems all but inevitable.



AI can be divided into four categories, based on the type and complexity of the tasks a system is able to perform. For example, automated spam filtering falls into the most basic class of AI, while the far-off potential for machines that can perceive people’s thoughts and emotions is part of an entirely different AI subset.
A reactive machine follows the most basic of AI principles and, as its name implies, is capable of only using its intelligence to perceive and react to the world in front of it. A reactive machine cannot store a memory and, as a result, cannot rely on past experiences to inform decision making in real time.
Perceiving the world directly means that reactive machines are designed to complete only a limited number of specialized duties. Intentionally narrowing a reactive machine’s worldview is not any sort of cost-cutting measure, however, and instead means that this type of AI will be more trustworthy and reliable — it will react the same way to the same stimuli every time.

A famous example of a reactive machine is Deep Blue, which was designed by IBM in the 1990s as a chess-playing supercomputer and defeated international grandmaster Gary Kasparov in a game. Deep Blue was only capable of identifying the pieces on a chess board and knowing how each moves based on the rules of chess, acknowledging each piece’s present position and determining what the most logical move would be at that moment. 


The computer was not pursuing future potential moves by its opponent or trying to put its own pieces in better position. Every turn was viewed as its own reality, separate from any other movement that was made beforehand


Another example of a game-playing reactive machine is Google’s AlphaGo. AlphaGo is also incapable of evaluating future moves but relies on its own neural network to evaluate developments of the present game, giving it an edge over Deep Blue in a more complex game. AlphaGo also bested world-class competitors of the game, defeating champion Go player Lee Sedol in 2016.

Though limited in scope and not easily altered, reactive machine AI can attain a level of complexity, and offers reliability when created to fulfill repeatable tasks.

 

Limited Memory
Limited memory AI has the ability to store previous data and predictions when gathering information and weighing potential decisions — essentially looking into the past for clues on what may come next. Limited memory AI is more complex and presents greater possibilities than reactive machines.

Limited memory AI is created when a team continuously trains a model in how to analyze and utilize new data or an AI environment is built so models can be automatically trained and renewed. 

When utilizing limited memory AI in ML, six steps must be followed: Training data must be created, the ML model must be created, the model must be able to make predictions, the model must be able to receive human or environmental feedback, that feedback must be stored as data, and these these steps must be reiterated as a cycle.

There are several ML models that utilize limited memory AI:

Reinforcement learning, which learns to make better predictions through repeated trial and error.
 
Recurrent neural networks (RNN), which uses sequential data to take information from prior inputs to influence the current input and output. These are commonly used for ordinal or temporal problems, such as language translation, natural language processing, speech recognition and image captioning. One subset of recurrent neural networks is known as long short term memory (LSTM), which utilizes past data to help predict the next item in a sequence. LTSMs view more recent information as most important when making predictions, and discount data from further in the past while still utilizing it to form conclusions.
 
Evolutionary generative adversarial networks (E-GAN), which evolve over time, growing to explore slightly modified paths based off of previous experiences with every new decision. This model is constantly in pursuit of a better path and utilizes simulations and statistics, or chance, to predict outcomes throughout its evolutionary mutation cycle.
 
Transformers, which are networks of nodes that learn how to do a certain task by training on existing data. Instead of having to group elements together, transformers are able to run processes so that every element in the input data pays attention to every other element. Researchers refer to this as “self-attention,” meaning that as soon as it starts training, a transformer can see traces of the entire data set.
 

Theory of Mind
Theory of mind is just that — theoretical. We have not yet achieved the technological and scientific capabilities necessary to reach this next level of AI.

The concept is based on the psychological premise of understanding that other living things have thoughts and emotions that affect the behavior of one’s self. In terms of AI machines, this would mean that AI could comprehend how humans, animals and other machines feel and make decisions through self-reflection and determination, and then will utilize that information to make decisions of their own. Essentially, machines would have to be able to grasp and process the concept of “mind,” the fluctuations of emotions in decision making and a litany of other psychological concepts in real time, creating a two-way relationship between people and AI.
Besides narrow AI and AGI, some consider there to be a third category known as superintelligence. For now, this is a completely hypothetical situation in which machines are completely self-aware, even surpassing the likes of human intelligence in practically every field, from science to social skills. In theory, this could be achieved through a single computer, a network of computers or something completely different, as long as it is conscious and has subjective experiences.
Nick Bostrom, a founding professor and leader of Oxford’s Future of Humanity Institute, appears to have coined the term back in 1998, and predicted that we will have achieved superhuman artificial intelligence within the first third of the 21st century. He went on to say that the likelihood of this happening will likely depend on how quickly neuroscience can better understand and replicate the human brain. Creating superintelligence by imitating the human brain, he added, will require not only sufficiently powerful hardware, but also an “adequate initial architecture” and a “rich flux of sensory input.”
AI has many uses — from boosting vaccine development to automating detection of potential fraud. 
AI private market activity saw a record-setting year in 2021, according to CB Insights, with global funding up 108 percent compared to 2020. Because of its fast-paced adoption, AI is making waves in a variety of industries.
Business Insider Intelligence’s 2022 report on AI in banking found more than half of financial services companies already use AI solutions for risk management and revenue generation. The application of AI in banking could lead to upwards of $400 billion in savings.
As for medicine, a 2021 World Health Organization report noted that while integrating AI into the healthcare field comes with challenges, the technology “holds great promise,” as it could lead to benefits like more informed health policy and improvements in the accuracy of diagnosing patients.
AI has also made its mark on entertainment. The global market for AI in media and entertainment is estimated to reach $99.48 billion by 2030, growing from a value of $10.87 billion in 2021, according to Grand View Research. That expansion includes AI uses like recognizing plagiarism and developing high-definition graphics.
 
While AI is certainly viewed as an important and quickly evolving asset, this emerging field comes with its share of downsides.
The Pew Research Center surveyed 10,260 Americans in 2021 on their attitudes toward AI. The results found 45 percent of respondents are equally excited and concerned, and 37 percent are more concerned than excited. Additionally, more than 40 percent of respondents said they considered driverless cars to be bad for society. Yet the idea of using AI to identify the spread of false information on social media was more well received, with close to 40 percent of those surveyed labeling it a good idea.
AI is a boon for improving productivity and efficiency while at the same time reducing the potential for human error. But there are also some disadvantages, like development costs and the possibility for automated machines to replace human jobs. It’s worth noting, however, that the artificial intelligence industry stands to create jobs, too — some of which have not even been invented yet.


"""

"""Preprocessing the input text"""

preprocessed_text=text.strip().replace('\n','')
t5input_text='summerize:' + preprocessed_text

len(t5input_text.split())

tokenized_text=tokenizer.encode(t5input_text, return_tensors='pt',max_length=2000).to(device)

"""Tokenizing

Summerize
"""

summary_ids= model.generate(tokenized_text, min_length=120)
summary=tokenizer.decode(summary_ids[0], skip_special_tokens=True)

summary